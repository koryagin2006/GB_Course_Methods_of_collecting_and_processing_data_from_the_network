# -*- coding: utf-8 -*-
"""Lesson_4 DZ.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/koryagin2006/GB_Course_Methods_of_collecting_and_processing_data_from_the_network/blob/master/Lesson_4%20%D0%9F%D0%B0%D1%80%D1%81%D0%B8%D0%BD%D0%B3%20HTML.%20XPath/Lesson_4%20DZ.ipynb

# Задание

1. Написать приложение, которое собирает основные новости с сайтов `mail.ru, lenta.ru, yandex.news`
2. Сложить все новости в БД

Для парсинга использовать xpath. Структура данных должна содержать:
- название источника,
- наименование новости,
- ссылку на новость,
- дата публикации

### Подключение библиотек
"""

import requests
from pprint import pprint
from lxml import html
from pymongo import MongoClient
from datetime import datetime
import json

"""---

### Запуск сервера
"""

try:
    client = MongoClient('localhost', 27017)
    print('connected successfully')
except:
    print('bad connection')

db = client['database_news']  # создание БД
news_from_3_sites = db.news_from_3_sites  # содание коллекции

"""---"""

main_link_mail = 'https://https://news.mail.ru'
main_link_ya = 'https://yandex.ru/news/'
main_link_lenta = 'https://lenta.ru'

header = {'User-Agent': '''Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) 
Chrome/80.0.3987.132 Safari/537.36'''}


def tree(main_link):
    response = requests.get(main_link, headers=header).text
    tree = html.fromstring(response)
    return tree


# - название источника,
# - наименование новости,
# - ссылку на новость,
# - дата публикации

# news_all = []

"""### Сбор новостей

#### https://yandex.ru/news/
"""

news_list_ya = tree(main_link_ya).xpath("//div[@class='story__topic']")

for news in news_list_ya:
    news_data = {}

    name = str(news.xpath(".//h2[@class='story__title']/a/text()")[0])
    origin = str(news.xpath("..//div[@class='story__info']/div[1]/text()")[0])[:-5]
    href = 'https://yandex.ru' + str(news.xpath(".//h2[@class='story__title']/a/@href")[0])
    date_time = str(datetime.now())[:10] + str(news.xpath("..//div[@class='story__info']/div[1]/text()")[0])[-5:]

    news_data['1 название источника'] = origin
    news_data['2 наименование новости'] = name
    news_data['3 ссылка на новость'] = href
    news_data['4 дата публикации'] = date_time

    news_from_3_sites.insert_one(news_data)

"""#### https://lenta.ru/"""

news_list_lenta = tree(main_link_lenta).xpath(
    "//section[@class='row b-top7-for-main js-top-seven']/div[@class='span4']/div")

for news in news_list_lenta[:-1]:
    news_data = {}

    name = str(news.xpath(".//a[1]/text()")[0])
    origin = main_link_lenta
    href = main_link_lenta + str(news.xpath("./a/@href")[0])
    date_time = str(news.xpath(".//a[1]/time[1]/@title")[0])

    news_data['1 название источника'] = origin
    news_data['2 наименование новости'] = name
    news_data['3 ссылка на новость'] = href
    news_data['4 дата публикации'] = date_time

    news_from_3_sites.insert_one(news_data)

"""#### https://news.mail.ru/"""

# tree_mail = tree(main_link_mail)

# news_list_mail_1 = tree_mail.xpath("//td[@class='daynews__main']//span[@class='photo__title photo__title_new photo__title_new_hidden js-topnews__notification']")
# # news_list_mail_3 = tree_mail.xpath("//a[@class='newsitem__title link-holder']")

# for news in news_list_mail:
#     news_data={}

#     name = ''
#     origin = ''
#     href = ''
#     date_time = ''

#     print(name)
#     break
# #     name = str(news.xpath(".//a[1]/text()")[0])
# #     origin = main_link_lenta
# #     href = main_link_lenta + str(news.xpath("./a/@href")[0])
# #     date_time = str(news.xpath(".//a[1]/time[1]/@title")[0])

# #     news_data['1 название источника'] = origin
# #     news_data['2 наименование новости'] = name
# #     news_data['3 ссылка на новость'] = href
# #     news_data['4 дата публикации'] = date_time

# #     news_from_3_sites.insert_one(news_data)

"""### Проверка"""

from pandas import DataFrame

cursor = news_from_3_sites.find({})
DataFrame(list(cursor)).drop(['_id'], axis=1)

"""---

При необходимости - очищение коллекции
"""

# news_from_3_sites.delete_many({})
